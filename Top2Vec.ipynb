{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Top2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCY34g2vABYe",
        "outputId": "341f877a-c9a9-40bc-d580-bb17c003bed0"
      },
      "source": [
        "pip install top2vec"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: top2vec in /usr/local/lib/python3.7/dist-packages (1.0.26)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.21.1)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec) (3.6.0)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.5.0)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec) (0.8.27)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec) (1.1.5)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec) (0.5.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec) (5.1.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (0.29.24)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec) (1.0.1)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.5.4)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec) (0.51.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec) (57.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec) (2018.9)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otLdSANgBFoU",
        "outputId": "544a089c-8086-4380-9002-4a9635e82723"
      },
      "source": [
        "\n",
        "from top2vec import Top2Vec\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
        "\n",
        "model = Top2Vec(documents=newsgroups.data, speed=\"learn\", workers=8)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
            "2021-08-14 04:01:46,676 - top2vec - INFO - Pre-processing documents for training\n",
            "2021-08-14 04:01:56,685 - top2vec - INFO - Creating joint document/word embedding\n",
            "2021-08-14 04:13:23,729 - top2vec - INFO - Creating lower dimension embedding of documents\n",
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n",
            "2021-08-14 04:14:10,934 - top2vec - INFO - Finding dense areas of documents\n",
            "2021-08-14 04:14:13,982 - top2vec - INFO - Finding topics\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nDQ_CqH6AEwC",
        "outputId": "89ddfe46-13df-4684-ea1b-dfe0293d3c4f"
      },
      "source": [
        "pip install top2vec[sentence_encoders]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: top2vec[sentence_encoders] in /usr/local/lib/python3.7/dist-packages (1.0.26)\n",
            "Requirement already satisfied: hdbscan>=0.8.27 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.8.27)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.21.1)\n",
            "Requirement already satisfied: umap-learn>=0.5.1 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.5.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (1.5.0)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (3.6.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.5.0-cp37-cp37m-manylinux1_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 38.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (2.5.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.7/dist-packages (from top2vec[sentence_encoders]) (0.12.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec[sentence_encoders]) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec[sentence_encoders]) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->top2vec[sentence_encoders]) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->top2vec[sentence_encoders]) (0.29.24)\n",
            "Requirement already satisfied: pynndescent>=0.5 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.5.4)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (57.2.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.1->top2vec[sentence_encoders]) (0.34.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->top2vec[sentence_encoders]) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.12)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.1.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.37.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.4.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.6.3)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.34.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.5.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.3.0)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.5.0.dev2021032900)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.6.0-cp37-cp37m-manylinux2010_x86_64.whl (458.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 458.3 MB 7.4 kB/s \n",
            "\u001b[?25hCollecting clang~=5.0\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "Collecting keras~=2.6\n",
            "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 46.3 MB/s \n",
            "\u001b[?25hCollecting tensorboard~=2.6\n",
            "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 31.8 MB/s \n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
            "  Downloading grpcio-1.39.0-cp37-cp37m-manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3 MB 33.0 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator~=2.6\n",
            "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 59.4 MB/s \n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.5.1-cp37-cp37m-manylinux2010_x86_64.whl (454.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.4 MB 10 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.4.3-cp37-cp37m-manylinux2010_x86_64.whl (394.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.5 MB 183 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (3.7.4.3)\n",
            "Collecting grpcio~=1.32.0\n",
            "  Downloading grpcio-1.32.0-cp37-cp37m-manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 39.8 MB/s \n",
            "\u001b[?25hCollecting h5py~=2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 47.2 MB/s \n",
            "\u001b[?25hCollecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow->top2vec[sentence_encoders]) (2.5.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.4.2-cp37-cp37m-manylinux2010_x86_64.whl (394.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.5 MB 32 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3 MB 5.9 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.4.0-cp37-cp37m-manylinux2010_x86_64.whl (394.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 394.7 MB 16 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
            "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 59.7 MB/s \n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.3.4-cp37-cp37m-manylinux2010_x86_64.whl (320.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.6 MB 46 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[K     |████████████████████████████████| 459 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.3.3-cp37-cp37m-manylinux2010_x86_64.whl (320.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.5 MB 14 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.3.2-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 13 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.3.1-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 17 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.3.0-cp37-cp37m-manylinux2010_x86_64.whl (320.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.4 MB 17 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.2.3-cp37-cp37m-manylinux2010_x86_64.whl (516.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.4 MB 19 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.2.2-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 22 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.2.1-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 31 kB/s \n",
            "\u001b[?25h  Downloading tensorflow-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl (516.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 516.2 MB 4.5 kB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.3.0,>=2.2.0\n",
            "  Downloading tensorflow_estimator-2.2.0-py2.py3-none-any.whl (454 kB)\n",
            "\u001b[K     |████████████████████████████████| 454 kB 57.1 MB/s \n",
            "\u001b[?25hCollecting tensorboard<2.3.0,>=2.2.0\n",
            "  Downloading tensorboard-2.2.2-py3-none-any.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (1.8.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (1.34.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (0.4.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (4.6.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<2.3.0,>=2.2.0->tensorflow->top2vec[sentence_encoders]) (3.5.0)\n",
            "INFO: pip is looking at multiple versions of tensorflow-text to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.4.3-cp37-cp37m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 41.7 MB/s \n",
            "\u001b[?25h  Downloading tensorflow_text-2.4.2-cp37-cp37m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 22.7 MB/s \n",
            "\u001b[?25h  Downloading tensorflow_text-2.4.1-cp37-cp37m-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 43.1 MB/s \n",
            "\u001b[?25h  Downloading tensorflow_text-2.3.0-cp37-cp37m-manylinux1_x86_64.whl (2.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6 MB 42.6 MB/s \n",
            "\u001b[?25h  Downloading tensorflow_text-2.2.1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 40.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from wordcloud->top2vec[sentence_encoders]) (7.1.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, h5py, gast, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.5.0\n",
            "    Uninstalling tensorflow-estimator-2.5.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.5.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.5.0\n",
            "    Uninstalling tensorflow-2.5.0:\n",
            "      Successfully uninstalled tensorflow-2.5.0\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 tensorboard-2.2.2 tensorflow-2.2.0 tensorflow-estimator-2.2.0 tensorflow-text-2.2.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "h5py",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "id": "CVLDENf1A0MM",
        "outputId": "2d4255dd-6ae3-42cc-e0d0-d8f8400310c9"
      },
      "source": [
        "from top2vec import Top2Vec\n",
        "\n",
        "model=Top2Vec(documents=['''The greenhouse effect is a natural process that warms the Earth’s surface. When the Sun’s energy reaches the Earth’s atmosphere, some of it is reflected back to space and the rest is absorbed and re-radiated by greenhouse gases.''',\n",
        "\n",
        "'''Greenhouse gases include water vapour, carbon dioxide, methane, nitrous oxide, ozone and some artificial chemicals such as chlorofluorocarbons (CFCs).''',\n",
        "\n",
        "'''The absorbed energy warms the atmosphere and the surface of the Earth. This process maintains the Earth’s temperature at around 33 degrees Celsius warmer than it would otherwise be, allowing life on Earth to exist.'''], min_count=1, embedding_model='universal-sentence-encoder')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-985850ecdda0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m'''Greenhouse gases include water vapour, carbon dioxide, methane, nitrous oxide, ozone and some artificial chemicals such as chlorofluorocarbons (CFCs).'''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m '''The absorbed energy warms the atmosphere and the surface of the Earth. This process maintains the Earth’s temperature at around 33 degrees Celsius warmer than it would otherwise be, allowing life on Earth to exist.'''], min_count=1, embedding_model='universal-sentence-encoder')\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/top2vec/Top2Vec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, documents, min_count, embedding_model, embedding_model_path, speed, use_corpus_file, document_ids, keep_documents, workers, tokenizer, use_embedding_model_tokenizer, umap_args, hdbscan_args, verbose)\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_import_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pre-processing documents for training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/top2vec/Top2Vec.py\u001b[0m in \u001b[0;36m_check_import_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    822\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_model\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'distiluse-base-multilingual-cased'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAVE_TENSORFLOW\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 raise ImportError(f\"{self.embedding_model} is not available.\\n\\n\"\n\u001b[0m\u001b[1;32m    825\u001b[0m                                   \u001b[0;34m\"Try: pip install top2vec[sentence_encoders]\\n\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m                                   \"Alternatively try: pip install tensorflow tensorflow_hub tensorflow_text\")\n",
            "\u001b[0;31mImportError\u001b[0m: universal-sentence-encoder is not available.\n\nTry: pip install top2vec[sentence_encoders]\n\nAlternatively try: pip install tensorflow tensorflow_hub tensorflow_text",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfczQyNhMDmj"
      },
      "source": [
        "topic_words, word_scores, topic_nums = model.get_topics(1)\n",
        "topic_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDrJBbVnh_o3"
      },
      "source": [
        "newsgroups.data[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D6XHIr30PTS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}