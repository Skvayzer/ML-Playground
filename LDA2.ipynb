{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LDA2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIzNrD5xeCdh",
        "outputId": "ea480bbe-0b3e-4769-b296-4b7a445b8019"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "nltk.download('wordnet')      #download if using this module for the first time\n",
        "\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')    #download if using this module for the first time\n",
        "\n",
        "\n",
        "#For Gensim\n",
        "import gensim\n",
        "import string\n",
        "from gensim import corpora\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z9tXlsAeFYf",
        "outputId": "62b1ca06-2547-416c-8ec8-50c196a66570"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "compileddoc = fetch_20newsgroups(subset='train', shuffle = True)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "cpnjLz89wI1i",
        "outputId": "95287aec-ccaf-4c3c-99ad-64a9fa5114e0"
      },
      "source": [
        "compileddoc['data'][3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'From: jgreen@amber (Joe Green)\\nSubject: Re: Weitek P9000 ?\\nOrganization: Harris Computer Systems Division\\nLines: 14\\nDistribution: world\\nNNTP-Posting-Host: amber.ssd.csd.harris.com\\nX-Newsreader: TIN [version 1.1 PL9]\\n\\nRobert J.C. Kyanko (rob@rjck.UUCP) wrote:\\n> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\\n> > Anyone know about the Weitek P9000 graphics chip?\\n> As far as the low-level stuff goes, it looks pretty nice.  It\\'s got this\\n> quadrilateral fill command that requires just the four points.\\n\\nDo you have Weitek\\'s address/phone number?  I\\'d like to get some information\\nabout this chip.\\n\\n--\\nJoe Green\\t\\t\\t\\tHarris Corporation\\njgreen@csd.harris.com\\t\\t\\tComputer Systems Division\\n\"The only thing that really scares me is a person with no sense of humor.\"\\n\\t\\t\\t\\t\\t\\t-- Jonathan Winters\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MJpcnhBeiaH"
      },
      "source": [
        "stopwords = set(stopwords.words('english'))\n",
        "exclude = set(string.punctuation)\n",
        "lemma = WordNetLemmatizer()\n",
        "\n",
        "def clean(document):\n",
        "    stopwordremoval = \" \".join([i for i in document.lower().split() if i not in stopwords])\n",
        "    punctuationremoval = ''.join(ch for ch in stopwordremoval if ch not in exclude)\n",
        "    normalized = \" \".join(lemma.lemmatize(word) for word in punctuationremoval.split())\n",
        "    return normalized\n",
        "\n",
        "final_doc = [clean(document).split() for document in compileddoc]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhcDzAPqemNH"
      },
      "source": [
        "dictionary = corpora.Dictionary(final_doc)\n",
        "\n",
        "DT_matrix = [dictionary.doc2bow(doc) for doc in final_doc]\n",
        "\n",
        "Lda_object = gensim.models.ldamodel.LdaModel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFPZ6zIGepqm",
        "outputId": "b360ebb1-ea5b-4914-ea45-6999c908e721"
      },
      "source": [
        "lda_model_1 = Lda_object(DT_matrix, num_topics=2, id2word = dictionary)\n",
        "\n",
        "print(lda_model_1.print_topics(num_topics=2, num_words=5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '0.267*\"target\" + 0.256*\"filename\" + 0.172*\"data\" + 0.163*\"descr\" + 0.141*\"targetnames\"'), (1, '0.257*\"targetnames\" + 0.236*\"descr\" + 0.227*\"data\" + 0.145*\"filename\" + 0.134*\"target\"')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTgm0SYTetXU",
        "outputId": "15ed1009-9701-4a35-e4e6-f54b1bc612ed"
      },
      "source": [
        "unseen_document = ''' This form of treatment may be helpful for people with depression and anxiety, and it may help improve the quality of life for people with physical health problems.2 Anyone can engage in music therapy; you donâ€™t need a background in music to experience its beneficial effects. '''\n",
        "unseen_document = compileddoc['data'][3]\n",
        "print(unseen_document)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From: jgreen@amber (Joe Green)\n",
            "Subject: Re: Weitek P9000 ?\n",
            "Organization: Harris Computer Systems Division\n",
            "Lines: 14\n",
            "Distribution: world\n",
            "NNTP-Posting-Host: amber.ssd.csd.harris.com\n",
            "X-Newsreader: TIN [version 1.1 PL9]\n",
            "\n",
            "Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\n",
            "> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\n",
            "> > Anyone know about the Weitek P9000 graphics chip?\n",
            "> As far as the low-level stuff goes, it looks pretty nice.  It's got this\n",
            "> quadrilateral fill command that requires just the four points.\n",
            "\n",
            "Do you have Weitek's address/phone number?  I'd like to get some information\n",
            "about this chip.\n",
            "\n",
            "--\n",
            "Joe Green\t\t\t\tHarris Corporation\n",
            "jgreen@csd.harris.com\t\t\tComputer Systems Division\n",
            "\"The only thing that really scares me is a person with no sense of humor.\"\n",
            "\t\t\t\t\t\t-- Jonathan Winters\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYNJ_SjMe1Jt",
        "outputId": "7f3065df-e017-4fb9-b81f-065d278916e4"
      },
      "source": [
        "import gensim\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.parsing.preprocessing import STOPWORDS\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")\n",
        "\n",
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "def preprocess(text):\n",
        "    result=[]\n",
        "    for token in gensim.utils.simple_preprocess(text) :\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "            \n",
        "    return result\n",
        "# Data preprocessing step for the unseen document\n",
        "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
        "\n",
        "for index, score in sorted(lda_model_1[bow_vector], key=lambda tup: -1*tup[1]):\n",
        "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model_1.print_topic(index, 5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 0.5\t Topic: 0.267*\"target\" + 0.256*\"filename\" + 0.172*\"data\" + 0.163*\"descr\" + 0.141*\"targetnames\"\n",
            "Score: 0.5\t Topic: 0.257*\"targetnames\" + 0.236*\"descr\" + 0.227*\"data\" + 0.145*\"filename\" + 0.134*\"target\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFK7g5BNe4AM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}